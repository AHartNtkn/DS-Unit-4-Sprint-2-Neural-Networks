diff --git a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
index 7e1d510..9651168 100644
--- a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
+++ b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
@@ -73,7 +73,16 @@
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
+      "57344/57026 [==============================] - 0s 0us/step\n"
+     ]
+    }
+   ],
    "source": [
     "from tensorflow.keras.datasets import boston_housing\n",
     "\n",
@@ -96,7 +105,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 3,
    "metadata": {},
    "outputs": [
     {
@@ -160,7 +169,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 4,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -177,164 +186,164 @@
      "text": [
       "Train on 404 samples, validate on 102 samples\n",
       "Epoch 1/75\n",
-      "404/404 [==============================] - 2s 4ms/sample - loss: 498.2045 - mse: 498.2046 - mae: 20.2543 - val_loss: 421.5039 - val_mse: 421.5038 - val_mae: 18.3349\n",
+      "404/404 [==============================] - 1s 3ms/sample - loss: 467.4155 - mse: 467.4155 - mae: 19.3901 - val_loss: 366.1949 - val_mse: 366.1949 - val_mae: 16.9999\n",
       "Epoch 2/75\n",
-      "404/404 [==============================] - 0s 347us/sample - loss: 249.6985 - mse: 249.6985 - mae: 13.2672 - val_loss: 111.3743 - val_mse: 111.3743 - val_mae: 8.6210\n",
+      "404/404 [==============================] - 0s 246us/sample - loss: 202.5861 - mse: 202.5861 - mae: 11.6459 - val_loss: 72.1596 - val_mse: 72.1596 - val_mae: 7.1184\n",
       "Epoch 3/75\n",
-      "404/404 [==============================] - 0s 344us/sample - loss: 56.6755 - mse: 56.6755 - mae: 5.4817 - val_loss: 39.1997 - val_mse: 39.1997 - val_mae: 4.9872\n",
+      "404/404 [==============================] - 0s 246us/sample - loss: 45.8463 - mse: 45.8463 - mae: 4.9942 - val_loss: 33.6212 - val_mse: 33.6212 - val_mae: 4.6576\n",
       "Epoch 4/75\n",
-      "404/404 [==============================] - 0s 364us/sample - loss: 28.3243 - mse: 28.3243 - mae: 3.7054 - val_loss: 26.9866 - val_mse: 26.9866 - val_mae: 4.0796\n",
+      "404/404 [==============================] - 0s 251us/sample - loss: 28.8632 - mse: 28.8632 - mae: 3.7837 - val_loss: 26.7357 - val_mse: 26.7357 - val_mae: 4.0687\n",
       "Epoch 5/75\n",
-      "404/404 [==============================] - 0s 382us/sample - loss: 20.5281 - mse: 20.5281 - mae: 3.1209 - val_loss: 24.6172 - val_mse: 24.6172 - val_mae: 3.8052\n",
+      "404/404 [==============================] - 0s 262us/sample - loss: 23.9486 - mse: 23.9486 - mae: 3.4168 - val_loss: 24.7835 - val_mse: 24.7835 - val_mae: 3.8132\n",
       "Epoch 6/75\n",
-      "404/404 [==============================] - 0s 393us/sample - loss: 17.9283 - mse: 17.9283 - mae: 2.8665 - val_loss: 23.6524 - val_mse: 23.6524 - val_mae: 3.6746\n",
+      "404/404 [==============================] - 0s 266us/sample - loss: 21.1138 - mse: 21.1138 - mae: 3.1564 - val_loss: 22.4667 - val_mse: 22.4667 - val_mae: 3.6334\n",
       "Epoch 7/75\n",
-      "404/404 [==============================] - 0s 440us/sample - loss: 16.9179 - mse: 16.9179 - mae: 2.8781 - val_loss: 23.4620 - val_mse: 23.4620 - val_mae: 3.5778\n",
+      "404/404 [==============================] - 0s 261us/sample - loss: 19.4284 - mse: 19.4284 - mae: 3.0161 - val_loss: 22.2686 - val_mse: 22.2686 - val_mae: 3.6056\n",
       "Epoch 8/75\n",
-      "404/404 [==============================] - 0s 366us/sample - loss: 15.1579 - mse: 15.1579 - mae: 2.6440 - val_loss: 24.1374 - val_mse: 24.1374 - val_mae: 3.5929\n",
+      "404/404 [==============================] - 0s 258us/sample - loss: 17.7225 - mse: 17.7225 - mae: 2.8762 - val_loss: 22.4145 - val_mse: 22.4145 - val_mae: 3.5281\n",
       "Epoch 9/75\n",
-      "404/404 [==============================] - 0s 367us/sample - loss: 14.1717 - mse: 14.1717 - mae: 2.5937 - val_loss: 24.4829 - val_mse: 24.4829 - val_mae: 3.5639\n",
+      "404/404 [==============================] - 0s 293us/sample - loss: 16.2215 - mse: 16.2215 - mae: 2.7882 - val_loss: 23.6603 - val_mse: 23.6603 - val_mae: 3.5898\n",
       "Epoch 10/75\n",
-      "404/404 [==============================] - 0s 359us/sample - loss: 13.5002 - mse: 13.5002 - mae: 2.5633 - val_loss: 25.0170 - val_mse: 25.0170 - val_mae: 3.5601\n",
+      "404/404 [==============================] - 0s 256us/sample - loss: 15.2427 - mse: 15.2427 - mae: 2.7249 - val_loss: 22.1718 - val_mse: 22.1718 - val_mae: 3.4057\n",
       "Epoch 11/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 12.8641 - mse: 12.8641 - mae: 2.4963 - val_loss: 25.1162 - val_mse: 25.1162 - val_mae: 3.5449\n",
+      "404/404 [==============================] - 0s 280us/sample - loss: 14.2725 - mse: 14.2725 - mae: 2.5737 - val_loss: 23.6196 - val_mse: 23.6196 - val_mae: 3.4969\n",
       "Epoch 12/75\n",
-      "404/404 [==============================] - 0s 351us/sample - loss: 12.4033 - mse: 12.4033 - mae: 2.5224 - val_loss: 25.0382 - val_mse: 25.0382 - val_mae: 3.4858\n",
+      "404/404 [==============================] - 0s 276us/sample - loss: 13.3977 - mse: 13.3977 - mae: 2.5780 - val_loss: 23.0044 - val_mse: 23.0044 - val_mae: 3.3276\n",
       "Epoch 13/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 12.2653 - mse: 12.2653 - mae: 2.4637 - val_loss: 26.7274 - val_mse: 26.7274 - val_mae: 3.6054\n",
+      "404/404 [==============================] - 0s 249us/sample - loss: 12.5527 - mse: 12.5527 - mae: 2.4943 - val_loss: 23.1341 - val_mse: 23.1341 - val_mae: 3.3225\n",
       "Epoch 14/75\n",
-      "404/404 [==============================] - 0s 368us/sample - loss: 11.8249 - mse: 11.8249 - mae: 2.4648 - val_loss: 25.2347 - val_mse: 25.2347 - val_mae: 3.4602\n",
+      "404/404 [==============================] - 0s 240us/sample - loss: 11.8945 - mse: 11.8945 - mae: 2.4227 - val_loss: 24.3281 - val_mse: 24.3281 - val_mae: 3.3559\n",
       "Epoch 15/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 11.3965 - mse: 11.3965 - mae: 2.4134 - val_loss: 25.3070 - val_mse: 25.3070 - val_mae: 3.4305\n",
+      "404/404 [==============================] - 0s 253us/sample - loss: 11.5332 - mse: 11.5332 - mae: 2.4146 - val_loss: 23.3214 - val_mse: 23.3214 - val_mae: 3.2365\n",
       "Epoch 16/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 11.0982 - mse: 11.0982 - mae: 2.3616 - val_loss: 25.0599 - val_mse: 25.0599 - val_mae: 3.3784\n",
+      "404/404 [==============================] - 0s 272us/sample - loss: 11.5760 - mse: 11.5760 - mae: 2.3826 - val_loss: 24.3333 - val_mse: 24.3333 - val_mae: 3.2753\n",
       "Epoch 17/75\n",
-      "404/404 [==============================] - 0s 365us/sample - loss: 11.1969 - mse: 11.1969 - mae: 2.3806 - val_loss: 25.1976 - val_mse: 25.1976 - val_mae: 3.3732\n",
+      "404/404 [==============================] - 0s 253us/sample - loss: 10.6373 - mse: 10.6373 - mae: 2.3278 - val_loss: 23.9632 - val_mse: 23.9632 - val_mae: 3.2290\n",
       "Epoch 18/75\n",
-      "404/404 [==============================] - 0s 369us/sample - loss: 10.9278 - mse: 10.9278 - mae: 2.3653 - val_loss: 24.2875 - val_mse: 24.2875 - val_mae: 3.3114\n",
+      "404/404 [==============================] - 0s 273us/sample - loss: 10.4167 - mse: 10.4167 - mae: 2.3056 - val_loss: 24.6640 - val_mse: 24.6640 - val_mae: 3.2265\n",
       "Epoch 19/75\n",
-      "404/404 [==============================] - 0s 365us/sample - loss: 10.5854 - mse: 10.5854 - mae: 2.3170 - val_loss: 26.1450 - val_mse: 26.1450 - val_mae: 3.3971\n",
+      "404/404 [==============================] - 0s 265us/sample - loss: 10.2307 - mse: 10.2307 - mae: 2.2752 - val_loss: 25.1513 - val_mse: 25.1513 - val_mae: 3.2542\n",
       "Epoch 20/75\n",
-      "404/404 [==============================] - 0s 401us/sample - loss: 10.2546 - mse: 10.2546 - mae: 2.2813 - val_loss: 26.5278 - val_mse: 26.5278 - val_mae: 3.4465\n",
+      "404/404 [==============================] - 0s 288us/sample - loss: 9.9687 - mse: 9.9687 - mae: 2.2361 - val_loss: 25.0204 - val_mse: 25.0204 - val_mae: 3.2587\n",
       "Epoch 21/75\n",
-      "404/404 [==============================] - 0s 380us/sample - loss: 10.1321 - mse: 10.1321 - mae: 2.2866 - val_loss: 24.0363 - val_mse: 24.0363 - val_mae: 3.2792\n",
+      "404/404 [==============================] - 0s 285us/sample - loss: 9.7054 - mse: 9.7054 - mae: 2.2377 - val_loss: 23.9690 - val_mse: 23.9690 - val_mae: 3.1449\n",
       "Epoch 22/75\n",
-      "404/404 [==============================] - 0s 421us/sample - loss: 9.9169 - mse: 9.9169 - mae: 2.2907 - val_loss: 23.7310 - val_mse: 23.7310 - val_mae: 3.2334\n",
+      "404/404 [==============================] - 0s 259us/sample - loss: 9.5941 - mse: 9.5941 - mae: 2.1940 - val_loss: 24.7162 - val_mse: 24.7162 - val_mae: 3.1908\n",
       "Epoch 23/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 9.6588 - mse: 9.6588 - mae: 2.2284 - val_loss: 23.6472 - val_mse: 23.6472 - val_mae: 3.2013\n",
+      "404/404 [==============================] - 0s 295us/sample - loss: 9.3272 - mse: 9.3272 - mae: 2.1712 - val_loss: 26.6909 - val_mse: 26.6909 - val_mae: 3.4019\n",
       "Epoch 24/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 9.6887 - mse: 9.6887 - mae: 2.2468 - val_loss: 23.5379 - val_mse: 23.5379 - val_mae: 3.1921\n",
+      "404/404 [==============================] - 0s 277us/sample - loss: 9.5047 - mse: 9.5047 - mae: 2.2346 - val_loss: 26.6362 - val_mse: 26.6362 - val_mae: 3.4137\n",
       "Epoch 25/75\n",
-      "404/404 [==============================] - 0s 373us/sample - loss: 9.4049 - mse: 9.4049 - mae: 2.1999 - val_loss: 23.7713 - val_mse: 23.7713 - val_mae: 3.2273\n",
+      "404/404 [==============================] - 0s 240us/sample - loss: 9.3222 - mse: 9.3222 - mae: 2.1785 - val_loss: 27.3082 - val_mse: 27.3082 - val_mae: 3.4272\n",
       "Epoch 26/75\n",
-      "404/404 [==============================] - 0s 359us/sample - loss: 9.2304 - mse: 9.2304 - mae: 2.1946 - val_loss: 23.5093 - val_mse: 23.5093 - val_mae: 3.2072\n",
+      "404/404 [==============================] - 0s 243us/sample - loss: 9.4216 - mse: 9.4216 - mae: 2.2144 - val_loss: 24.6052 - val_mse: 24.6052 - val_mae: 3.1721\n",
       "Epoch 27/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 9.0493 - mse: 9.0493 - mae: 2.1528 - val_loss: 23.7969 - val_mse: 23.7969 - val_mae: 3.2005\n",
+      "404/404 [==============================] - 0s 246us/sample - loss: 8.8564 - mse: 8.8564 - mae: 2.1208 - val_loss: 24.5085 - val_mse: 24.5085 - val_mae: 3.1709\n",
       "Epoch 28/75\n",
-      "404/404 [==============================] - 0s 359us/sample - loss: 8.9363 - mse: 8.9363 - mae: 2.1475 - val_loss: 22.1030 - val_mse: 22.1030 - val_mae: 3.0707\n",
+      "404/404 [==============================] - 0s 289us/sample - loss: 8.8096 - mse: 8.8096 - mae: 2.1158 - val_loss: 26.0622 - val_mse: 26.0622 - val_mae: 3.2290\n",
       "Epoch 29/75\n",
-      "404/404 [==============================] - 0s 373us/sample - loss: 8.7834 - mse: 8.7834 - mae: 2.1231 - val_loss: 22.5153 - val_mse: 22.5153 - val_mae: 3.1532\n",
+      "404/404 [==============================] - 0s 282us/sample - loss: 8.8642 - mse: 8.8642 - mae: 2.1177 - val_loss: 24.5716 - val_mse: 24.5716 - val_mae: 3.0609\n",
       "Epoch 30/75\n",
-      "404/404 [==============================] - 0s 371us/sample - loss: 8.7925 - mse: 8.7925 - mae: 2.1531 - val_loss: 22.0449 - val_mse: 22.0449 - val_mae: 3.1245\n",
+      "404/404 [==============================] - 0s 254us/sample - loss: 8.5541 - mse: 8.5541 - mae: 2.0834 - val_loss: 23.8800 - val_mse: 23.8800 - val_mae: 3.0587\n",
       "Epoch 31/75\n",
-      "404/404 [==============================] - 0s 374us/sample - loss: 9.1879 - mse: 9.1879 - mae: 2.2029 - val_loss: 22.1780 - val_mse: 22.1780 - val_mae: 3.0623\n",
+      "404/404 [==============================] - 0s 245us/sample - loss: 8.4770 - mse: 8.4770 - mae: 2.0491 - val_loss: 22.6672 - val_mse: 22.6672 - val_mae: 2.9772\n",
       "Epoch 32/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 8.7136 - mse: 8.7136 - mae: 2.1164 - val_loss: 21.9815 - val_mse: 21.9815 - val_mae: 3.0969\n",
+      "404/404 [==============================] - 0s 266us/sample - loss: 8.4486 - mse: 8.4486 - mae: 2.0676 - val_loss: 23.7259 - val_mse: 23.7259 - val_mae: 3.0138\n",
       "Epoch 33/75\n",
-      "404/404 [==============================] - 0s 371us/sample - loss: 8.3018 - mse: 8.3018 - mae: 2.0639 - val_loss: 21.0477 - val_mse: 21.0477 - val_mae: 2.9645\n",
+      "404/404 [==============================] - 0s 266us/sample - loss: 8.7632 - mse: 8.7632 - mae: 2.1175 - val_loss: 24.2083 - val_mse: 24.2083 - val_mae: 3.0649\n",
       "Epoch 34/75\n",
-      "404/404 [==============================] - 0s 362us/sample - loss: 8.4156 - mse: 8.4156 - mae: 2.0970 - val_loss: 22.6659 - val_mse: 22.6659 - val_mae: 3.1235\n",
+      "404/404 [==============================] - 0s 263us/sample - loss: 8.1052 - mse: 8.1052 - mae: 2.0088 - val_loss: 23.6393 - val_mse: 23.6393 - val_mae: 3.0602\n",
       "Epoch 35/75\n",
-      "404/404 [==============================] - 0s 350us/sample - loss: 8.2938 - mse: 8.2938 - mae: 2.0567 - val_loss: 20.9574 - val_mse: 20.9574 - val_mae: 2.9746\n",
+      "404/404 [==============================] - 0s 242us/sample - loss: 8.1688 - mse: 8.1688 - mae: 2.0201 - val_loss: 22.8373 - val_mse: 22.8373 - val_mae: 3.0012\n",
       "Epoch 36/75\n",
-      "404/404 [==============================] - 0s 357us/sample - loss: 8.0515 - mse: 8.0515 - mae: 2.0591 - val_loss: 23.2063 - val_mse: 23.2063 - val_mae: 3.1980\n",
+      "404/404 [==============================] - 0s 250us/sample - loss: 7.9562 - mse: 7.9562 - mae: 1.9992 - val_loss: 23.5433 - val_mse: 23.5433 - val_mae: 3.0738\n",
       "Epoch 37/75\n",
-      "404/404 [==============================] - 0s 381us/sample - loss: 8.1403 - mse: 8.1403 - mae: 2.0584 - val_loss: 24.5238 - val_mse: 24.5237 - val_mae: 3.3531\n",
+      "404/404 [==============================] - 0s 253us/sample - loss: 8.0259 - mse: 8.0259 - mae: 2.0104 - val_loss: 23.0198 - val_mse: 23.0198 - val_mae: 3.0573\n",
       "Epoch 38/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 8.0043 - mse: 8.0043 - mae: 2.0776 - val_loss: 22.5424 - val_mse: 22.5424 - val_mae: 3.1494\n",
+      "404/404 [==============================] - 0s 255us/sample - loss: 8.0952 - mse: 8.0952 - mae: 2.0323 - val_loss: 23.3885 - val_mse: 23.3885 - val_mae: 3.0224\n",
       "Epoch 39/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 8.1182 - mse: 8.1182 - mae: 2.0683 - val_loss: 19.7576 - val_mse: 19.7576 - val_mae: 2.8799\n",
+      "404/404 [==============================] - 0s 266us/sample - loss: 7.8411 - mse: 7.8411 - mae: 1.9780 - val_loss: 21.5214 - val_mse: 21.5214 - val_mae: 2.8951\n",
       "Epoch 40/75\n",
-      "404/404 [==============================] - 0s 374us/sample - loss: 7.8578 - mse: 7.8578 - mae: 2.0131 - val_loss: 20.7728 - val_mse: 20.7728 - val_mae: 2.9499\n",
+      "404/404 [==============================] - 0s 253us/sample - loss: 8.0530 - mse: 8.0530 - mae: 1.9959 - val_loss: 21.4612 - val_mse: 21.4612 - val_mae: 2.9044\n",
       "Epoch 41/75\n",
-      "404/404 [==============================] - 0s 382us/sample - loss: 7.5711 - mse: 7.5711 - mae: 1.9896 - val_loss: 20.6170 - val_mse: 20.6170 - val_mae: 2.9936\n",
+      "404/404 [==============================] - 0s 242us/sample - loss: 7.9501 - mse: 7.9501 - mae: 1.9917 - val_loss: 23.1425 - val_mse: 23.1425 - val_mae: 2.9585\n",
       "Epoch 42/75\n",
-      "404/404 [==============================] - 0s 385us/sample - loss: 7.5822 - mse: 7.5822 - mae: 1.9683 - val_loss: 20.8541 - val_mse: 20.8541 - val_mae: 3.0054\n",
+      "404/404 [==============================] - 0s 262us/sample - loss: 7.5707 - mse: 7.5707 - mae: 1.9488 - val_loss: 21.5866 - val_mse: 21.5866 - val_mae: 2.9121\n",
       "Epoch 43/75\n",
-      "404/404 [==============================] - 0s 408us/sample - loss: 7.4533 - mse: 7.4533 - mae: 1.9645 - val_loss: 20.4473 - val_mse: 20.4473 - val_mae: 2.8861\n",
+      "404/404 [==============================] - 0s 283us/sample - loss: 7.6157 - mse: 7.6157 - mae: 1.9421 - val_loss: 22.0577 - val_mse: 22.0577 - val_mae: 2.9566\n",
       "Epoch 44/75\n",
-      "404/404 [==============================] - 0s 396us/sample - loss: 7.5226 - mse: 7.5226 - mae: 1.9509 - val_loss: 20.5193 - val_mse: 20.5193 - val_mae: 2.9619\n",
+      "404/404 [==============================] - 0s 269us/sample - loss: 7.4659 - mse: 7.4659 - mae: 1.9331 - val_loss: 21.8949 - val_mse: 21.8949 - val_mae: 2.8968\n",
       "Epoch 45/75\n",
-      "404/404 [==============================] - 0s 355us/sample - loss: 7.2819 - mse: 7.2819 - mae: 1.9350 - val_loss: 21.4862 - val_mse: 21.4862 - val_mae: 2.9908\n",
+      "404/404 [==============================] - 0s 266us/sample - loss: 7.3789 - mse: 7.3789 - mae: 1.9292 - val_loss: 20.7262 - val_mse: 20.7262 - val_mae: 2.8386\n",
       "Epoch 46/75\n",
-      "404/404 [==============================] - 0s 354us/sample - loss: 7.0130 - mse: 7.0130 - mae: 1.9152 - val_loss: 20.1577 - val_mse: 20.1577 - val_mae: 2.9370\n",
+      "404/404 [==============================] - 0s 243us/sample - loss: 7.4191 - mse: 7.4191 - mae: 1.9488 - val_loss: 21.7397 - val_mse: 21.7397 - val_mae: 2.8601\n",
       "Epoch 47/75\n",
-      "404/404 [==============================] - 0s 375us/sample - loss: 6.9431 - mse: 6.9431 - mae: 1.8819 - val_loss: 21.1210 - val_mse: 21.1210 - val_mae: 2.9746\n",
+      "404/404 [==============================] - 0s 255us/sample - loss: 7.3864 - mse: 7.3864 - mae: 1.9139 - val_loss: 23.1123 - val_mse: 23.1123 - val_mae: 2.9601\n",
       "Epoch 48/75\n",
-      "404/404 [==============================] - 0s 371us/sample - loss: 6.8982 - mse: 6.8982 - mae: 1.9037 - val_loss: 19.2999 - val_mse: 19.2999 - val_mae: 2.8638\n",
+      "404/404 [==============================] - 0s 255us/sample - loss: 7.3193 - mse: 7.3193 - mae: 1.9079 - val_loss: 21.5589 - val_mse: 21.5589 - val_mae: 2.8526\n",
       "Epoch 49/75\n",
-      "404/404 [==============================] - 0s 368us/sample - loss: 6.9521 - mse: 6.9521 - mae: 1.8862 - val_loss: 20.7825 - val_mse: 20.7825 - val_mae: 2.9369\n",
+      "404/404 [==============================] - 0s 253us/sample - loss: 7.2528 - mse: 7.2528 - mae: 1.9282 - val_loss: 20.6782 - val_mse: 20.6782 - val_mae: 2.8107\n",
       "Epoch 50/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 6.8718 - mse: 6.8718 - mae: 1.8889 - val_loss: 20.0288 - val_mse: 20.0288 - val_mae: 2.8915\n",
+      "404/404 [==============================] - 0s 257us/sample - loss: 7.1415 - mse: 7.1415 - mae: 1.8913 - val_loss: 20.5387 - val_mse: 20.5387 - val_mae: 2.8125\n",
       "Epoch 51/75\n",
-      "404/404 [==============================] - 0s 354us/sample - loss: 6.7111 - mse: 6.7111 - mae: 1.8702 - val_loss: 20.4913 - val_mse: 20.4913 - val_mae: 3.0116\n",
+      "404/404 [==============================] - 0s 255us/sample - loss: 7.0731 - mse: 7.0731 - mae: 1.8966 - val_loss: 20.8667 - val_mse: 20.8667 - val_mae: 2.9394\n",
       "Epoch 52/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 6.7492 - mse: 6.7492 - mae: 1.8482 - val_loss: 18.3008 - val_mse: 18.3008 - val_mae: 2.7362\n",
+      "404/404 [==============================] - 0s 259us/sample - loss: 7.2894 - mse: 7.2894 - mae: 1.9160 - val_loss: 22.3085 - val_mse: 22.3085 - val_mae: 2.9615\n",
       "Epoch 53/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 6.6262 - mse: 6.6262 - mae: 1.8395 - val_loss: 18.1885 - val_mse: 18.1885 - val_mae: 2.6920\n",
+      "404/404 [==============================] - 0s 260us/sample - loss: 6.9510 - mse: 6.9510 - mae: 1.8882 - val_loss: 20.5313 - val_mse: 20.5313 - val_mae: 2.8329\n",
       "Epoch 54/75\n",
-      "404/404 [==============================] - 0s 369us/sample - loss: 6.7148 - mse: 6.7148 - mae: 1.8611 - val_loss: 18.5764 - val_mse: 18.5764 - val_mae: 2.6977\n",
+      "404/404 [==============================] - 0s 239us/sample - loss: 6.7257 - mse: 6.7257 - mae: 1.8109 - val_loss: 20.9438 - val_mse: 20.9438 - val_mae: 2.8547\n",
       "Epoch 55/75\n",
-      "404/404 [==============================] - 0s 358us/sample - loss: 6.5425 - mse: 6.5425 - mae: 1.8522 - val_loss: 19.5772 - val_mse: 19.5772 - val_mae: 2.8326\n",
+      "404/404 [==============================] - 0s 248us/sample - loss: 7.0654 - mse: 7.0654 - mae: 1.8884 - val_loss: 23.0052 - val_mse: 23.0052 - val_mae: 3.0691\n",
       "Epoch 56/75\n",
-      "404/404 [==============================] - 0s 423us/sample - loss: 6.3349 - mse: 6.3349 - mae: 1.8175 - val_loss: 19.0932 - val_mse: 19.0932 - val_mae: 2.8260\n",
+      "404/404 [==============================] - 0s 224us/sample - loss: 6.6300 - mse: 6.6300 - mae: 1.8397 - val_loss: 21.0214 - val_mse: 21.0214 - val_mae: 2.9146\n",
       "Epoch 57/75\n",
-      "404/404 [==============================] - 0s 375us/sample - loss: 6.4253 - mse: 6.4253 - mae: 1.7972 - val_loss: 20.4036 - val_mse: 20.4036 - val_mae: 2.9258\n",
+      "404/404 [==============================] - 0s 247us/sample - loss: 6.5258 - mse: 6.5258 - mae: 1.8185 - val_loss: 19.8895 - val_mse: 19.8895 - val_mae: 2.8057\n",
       "Epoch 58/75\n",
-      "404/404 [==============================] - 0s 362us/sample - loss: 6.2897 - mse: 6.2897 - mae: 1.7785 - val_loss: 21.2845 - val_mse: 21.2845 - val_mae: 3.0715\n",
+      "404/404 [==============================] - 0s 252us/sample - loss: 6.6401 - mse: 6.6401 - mae: 1.8410 - val_loss: 19.9244 - val_mse: 19.9244 - val_mae: 2.7574\n",
       "Epoch 59/75\n",
-      "404/404 [==============================] - 0s 378us/sample - loss: 6.7839 - mse: 6.7839 - mae: 1.9027 - val_loss: 18.6853 - val_mse: 18.6853 - val_mae: 2.7709\n",
+      "404/404 [==============================] - 0s 245us/sample - loss: 6.6178 - mse: 6.6178 - mae: 1.8415 - val_loss: 20.2878 - val_mse: 20.2878 - val_mae: 2.7591\n",
       "Epoch 60/75\n",
-      "404/404 [==============================] - 0s 395us/sample - loss: 6.7178 - mse: 6.7178 - mae: 1.8871 - val_loss: 19.5394 - val_mse: 19.5394 - val_mae: 2.8101\n",
+      "404/404 [==============================] - 0s 238us/sample - loss: 6.5957 - mse: 6.5957 - mae: 1.8305 - val_loss: 20.0799 - val_mse: 20.0799 - val_mae: 2.7394\n",
       "Epoch 61/75\n",
-      "404/404 [==============================] - 0s 366us/sample - loss: 6.4152 - mse: 6.4152 - mae: 1.8175 - val_loss: 18.2377 - val_mse: 18.2377 - val_mae: 2.7450\n",
+      "404/404 [==============================] - 0s 242us/sample - loss: 6.3573 - mse: 6.3573 - mae: 1.7783 - val_loss: 18.2746 - val_mse: 18.2746 - val_mae: 2.6834\n",
       "Epoch 62/75\n",
-      "404/404 [==============================] - 0s 384us/sample - loss: 5.9727 - mse: 5.9727 - mae: 1.7630 - val_loss: 19.0252 - val_mse: 19.0252 - val_mae: 2.7960\n",
+      "404/404 [==============================] - 0s 288us/sample - loss: 6.4918 - mse: 6.4917 - mae: 1.8149 - val_loss: 18.8201 - val_mse: 18.8201 - val_mae: 2.6794\n",
       "Epoch 63/75\n",
-      "404/404 [==============================] - 0s 380us/sample - loss: 6.0973 - mse: 6.0973 - mae: 1.8071 - val_loss: 18.8069 - val_mse: 18.8069 - val_mae: 2.8894\n",
+      "404/404 [==============================] - 0s 395us/sample - loss: 6.1523 - mse: 6.1523 - mae: 1.7500 - val_loss: 19.9265 - val_mse: 19.9265 - val_mae: 2.7125\n",
       "Epoch 64/75\n",
-      "404/404 [==============================] - 0s 362us/sample - loss: 6.1074 - mse: 6.1074 - mae: 1.7978 - val_loss: 18.4702 - val_mse: 18.4702 - val_mae: 2.7851\n",
+      "404/404 [==============================] - 0s 260us/sample - loss: 6.1941 - mse: 6.1941 - mae: 1.7512 - val_loss: 19.8319 - val_mse: 19.8319 - val_mae: 2.7627\n",
       "Epoch 65/75\n",
-      "404/404 [==============================] - 0s 369us/sample - loss: 5.9329 - mse: 5.9329 - mae: 1.7545 - val_loss: 18.5321 - val_mse: 18.5321 - val_mae: 2.7933\n",
+      "404/404 [==============================] - 0s 250us/sample - loss: 6.0381 - mse: 6.0381 - mae: 1.7487 - val_loss: 20.4414 - val_mse: 20.4414 - val_mae: 2.7990\n",
       "Epoch 66/75\n",
-      "404/404 [==============================] - 0s 341us/sample - loss: 5.7473 - mse: 5.7473 - mae: 1.7211 - val_loss: 18.5536 - val_mse: 18.5536 - val_mae: 2.8010\n",
+      "404/404 [==============================] - 0s 231us/sample - loss: 6.0277 - mse: 6.0277 - mae: 1.7622 - val_loss: 18.8414 - val_mse: 18.8414 - val_mae: 2.6849\n",
       "Epoch 67/75\n",
-      "404/404 [==============================] - 0s 339us/sample - loss: 5.8866 - mse: 5.8866 - mae: 1.7224 - val_loss: 18.0067 - val_mse: 18.0067 - val_mae: 2.7054\n",
+      "404/404 [==============================] - 0s 258us/sample - loss: 5.9107 - mse: 5.9107 - mae: 1.7020 - val_loss: 19.2437 - val_mse: 19.2437 - val_mae: 2.7324\n",
       "Epoch 68/75\n",
-      "404/404 [==============================] - 0s 337us/sample - loss: 5.7885 - mse: 5.7885 - mae: 1.7391 - val_loss: 17.5502 - val_mse: 17.5502 - val_mae: 2.6767\n",
+      "404/404 [==============================] - 0s 267us/sample - loss: 6.0221 - mse: 6.0221 - mae: 1.7161 - val_loss: 18.5175 - val_mse: 18.5175 - val_mae: 2.6042\n",
       "Epoch 69/75\n",
-      "404/404 [==============================] - 0s 331us/sample - loss: 5.8809 - mse: 5.8809 - mae: 1.7542 - val_loss: 17.0280 - val_mse: 17.0280 - val_mae: 2.6404\n",
+      "404/404 [==============================] - 0s 227us/sample - loss: 5.9040 - mse: 5.9040 - mae: 1.7215 - val_loss: 18.5581 - val_mse: 18.5581 - val_mae: 2.6652\n",
       "Epoch 70/75\n",
-      "404/404 [==============================] - 0s 343us/sample - loss: 5.6028 - mse: 5.6028 - mae: 1.6972 - val_loss: 17.7188 - val_mse: 17.7188 - val_mae: 2.6979\n",
+      "404/404 [==============================] - 0s 218us/sample - loss: 5.8407 - mse: 5.8407 - mae: 1.7394 - val_loss: 18.5375 - val_mse: 18.5375 - val_mae: 2.6852\n",
       "Epoch 71/75\n",
-      "404/404 [==============================] - 0s 337us/sample - loss: 5.4361 - mse: 5.4361 - mae: 1.6741 - val_loss: 16.8852 - val_mse: 16.8852 - val_mae: 2.6126\n",
+      "404/404 [==============================] - 0s 254us/sample - loss: 5.6795 - mse: 5.6795 - mae: 1.6964 - val_loss: 19.0959 - val_mse: 19.0959 - val_mae: 2.7395\n",
       "Epoch 72/75\n",
-      "404/404 [==============================] - 0s 345us/sample - loss: 5.5608 - mse: 5.5608 - mae: 1.7252 - val_loss: 16.7483 - val_mse: 16.7483 - val_mae: 2.6063\n",
+      "404/404 [==============================] - 0s 243us/sample - loss: 5.7627 - mse: 5.7627 - mae: 1.7048 - val_loss: 17.3730 - val_mse: 17.3730 - val_mae: 2.5766\n",
       "Epoch 73/75\n",
-      "404/404 [==============================] - 0s 341us/sample - loss: 5.5022 - mse: 5.5022 - mae: 1.6912 - val_loss: 17.6786 - val_mse: 17.6786 - val_mae: 2.7316\n",
+      "404/404 [==============================] - 0s 249us/sample - loss: 5.6232 - mse: 5.6232 - mae: 1.6828 - val_loss: 18.4615 - val_mse: 18.4615 - val_mae: 2.7327\n",
       "Epoch 74/75\n",
-      "404/404 [==============================] - 0s 396us/sample - loss: 5.2794 - mse: 5.2794 - mae: 1.6478 - val_loss: 17.6115 - val_mse: 17.6115 - val_mae: 2.6773\n",
+      "404/404 [==============================] - 0s 253us/sample - loss: 5.9260 - mse: 5.9260 - mae: 1.7334 - val_loss: 19.1357 - val_mse: 19.1357 - val_mae: 2.6311\n",
       "Epoch 75/75\n",
-      "404/404 [==============================] - 0s 338us/sample - loss: 5.4796 - mse: 5.4796 - mae: 1.6876 - val_loss: 17.2835 - val_mse: 17.2835 - val_mae: 2.7126\n"
+      "404/404 [==============================] - 0s 255us/sample - loss: 5.5507 - mse: 5.5507 - mae: 1.6622 - val_loss: 17.3244 - val_mse: 17.3244 - val_mae: 2.5789\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x7f36340c6b38>"
+       "<tensorflow.python.keras.callbacks.History at 0x7efc8c14bbe0>"
       ]
      },
-     "execution_count": 3,
+     "execution_count": 4,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -439,14 +448,18 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 5,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 13561
     },
     "colab_type": "code",
+    "collapsed": true,
     "id": "2smXfriNAGn7",
+    "jupyter": {
+     "outputs_hidden": true
+    },
     "outputId": "ae996575-78e2-43fb-9dbe-5d44aaf0b430"
    },
    "outputs": [
@@ -462,13 +475,13 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Best: 0.65234375 using {'batch_size': 10, 'epochs': 20}\n",
-      "Means: 0.65234375, Stdev: 0.033298728782667764 with: {'batch_size': 10, 'epochs': 20}\n",
-      "Means: 0.6263020833333334, Stdev: 0.01813592223591682 with: {'batch_size': 20, 'epochs': 20}\n",
-      "Means: 0.6041666666666666, Stdev: 0.037782859709757574 with: {'batch_size': 40, 'epochs': 20}\n",
-      "Means: 0.5533854166666666, Stdev: 0.03210632293213009 with: {'batch_size': 60, 'epochs': 20}\n",
-      "Means: 0.61328125, Stdev: 0.024079742199097563 with: {'batch_size': 80, 'epochs': 20}\n",
-      "Means: 0.5611979166666666, Stdev: 0.038450060052691144 with: {'batch_size': 100, 'epochs': 20}\n"
+      "Best: 0.63671875 using {'batch_size': 10, 'epochs': 20}\n",
+      "Means: 0.63671875, Stdev: 0.016876928902103804 with: {'batch_size': 10, 'epochs': 20}\n",
+      "Means: 0.6184895833333334, Stdev: 0.018688411581259536 with: {'batch_size': 20, 'epochs': 20}\n",
+      "Means: 0.5572916666666666, Stdev: 0.1125078363397289 with: {'batch_size': 40, 'epochs': 20}\n",
+      "Means: 0.5598958333333334, Stdev: 0.08392126585584384 with: {'batch_size': 60, 'epochs': 20}\n",
+      "Means: 0.48046875, Stdev: 0.06282467750945218 with: {'batch_size': 80, 'epochs': 20}\n",
+      "Means: 0.59375, Stdev: 0.02834836075140266 with: {'batch_size': 100, 'epochs': 20}\n"
      ]
     }
    ],
@@ -541,7 +554,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 6,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -556,17 +569,17 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Best: 0.7044270833333334 using {'batch_size': 20, 'epochs': 200}\n",
-      "Means: 0.6666666666666666, Stdev: 0.028940248399600087 with: {'batch_size': 20, 'epochs': 20}\n",
-      "Means: 0.6588541666666666, Stdev: 0.028940248399600087 with: {'batch_size': 20, 'epochs': 40}\n",
-      "Means: 0.6848958333333334, Stdev: 0.03498705427745938 with: {'batch_size': 20, 'epochs': 60}\n",
-      "Means: 0.7044270833333334, Stdev: 0.018414239093399672 with: {'batch_size': 20, 'epochs': 200}\n"
+      "Best: 0.7408854166666666 using {'batch_size': 10, 'epochs': 200}\n",
+      "Means: 0.64453125, Stdev: 0.016572815184059706 with: {'batch_size': 10, 'epochs': 20}\n",
+      "Means: 0.703125, Stdev: 0.01149968862803105 with: {'batch_size': 10, 'epochs': 40}\n",
+      "Means: 0.6809895833333334, Stdev: 0.036966326996297885 with: {'batch_size': 10, 'epochs': 60}\n",
+      "Means: 0.7408854166666666, Stdev: 0.023938510821419574 with: {'batch_size': 10, 'epochs': 200}\n"
      ]
     }
    ],
    "source": [
     "# define the grid search parameters\n",
-    "param_grid = {'batch_size': [20],\n",
+    "param_grid = {'batch_size': [10],\n",
     "              'epochs': [20, 40, 60,200]}\n",
     "\n",
     "# Create Grid Search\n",
@@ -720,36 +733,221 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": 26,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# Function to create model, required for KerasClassifier\n",
+    "def create_model():\n",
+    "    # create model\n",
+    "    model = Sequential()\n",
+    "    model.add(Dense(64, activation='relu', input_shape=(inputs,)))\n",
+    "    model.add(Dense(64, activation='relu'))\n",
+    "    model.add(Dense(64, activation='relu'))\n",
+    "    model.add(Dense(1))\n",
+    "    # Compile Model\n",
+    "    model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae', 'accuracy'])\n",
+    "    return model\n",
+    "\n",
+    "# create model\n",
+    "model = KerasClassifier(build_fn=create_model, verbose=0)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 16,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "X =  x_train\n",
+    "y =  y_train"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 19,
    "metadata": {},
    "outputs": [
     {
      "data": {
-      "text/html": [
-       "\n",
-       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
-       "                Project page: <a href=\"https://app.wandb.ai/lambda-ds7/boston\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston</a><br/>\n",
-       "                Run page: <a href=\"https://app.wandb.ai/lambda-ds7/boston/runs/whw09rro\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston/runs/whw09rro</a><br/>\n",
-       "            "
-      ],
       "text/plain": [
-       "<IPython.core.display.HTML object>"
+       "(404, 13)"
       ]
      },
+     "execution_count": 19,
      "metadata": {},
-     "output_type": "display_data"
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "X.shape"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 20,
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "(404,)"
+      ]
+     },
+     "execution_count": 20,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "y.shape"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 27,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
+      "  warnings.warn(CV_WARNING, FutureWarning)\n"
+     ]
     },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.272844). Check your callbacks.\n"
+     ]
+    }
+   ],
+   "source": [
+    "param_grid = {'batch_size': [10], # [10, 20, 40, 60, 80, 100],\n",
+    "              'epochs': [20]}\n",
+    "\n",
+    "# Create Grid Search\n",
+    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
+    "grid_result = grid.fit(X, y, callbacks=[WandbCallback()])"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 30,
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "{'batch_size': 10, 'epochs': 20}"
+      ]
+     },
+     "execution_count": 30,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "grid_result.best_params_"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 29,
+   "metadata": {},
+   "outputs": [
     {
      "data": {
       "text/plain": [
-       "W&B Run: https://app.wandb.ai/lambda-ds7/boston/runs/whw09rro"
+       "['__abstractmethods__',\n",
+       " '__class__',\n",
+       " '__delattr__',\n",
+       " '__dict__',\n",
+       " '__dir__',\n",
+       " '__doc__',\n",
+       " '__eq__',\n",
+       " '__format__',\n",
+       " '__ge__',\n",
+       " '__getattribute__',\n",
+       " '__getstate__',\n",
+       " '__gt__',\n",
+       " '__hash__',\n",
+       " '__init__',\n",
+       " '__init_subclass__',\n",
+       " '__le__',\n",
+       " '__lt__',\n",
+       " '__module__',\n",
+       " '__ne__',\n",
+       " '__new__',\n",
+       " '__reduce__',\n",
+       " '__reduce_ex__',\n",
+       " '__repr__',\n",
+       " '__setattr__',\n",
+       " '__setstate__',\n",
+       " '__sizeof__',\n",
+       " '__str__',\n",
+       " '__subclasshook__',\n",
+       " '__weakref__',\n",
+       " '_abc_cache',\n",
+       " '_abc_negative_cache',\n",
+       " '_abc_negative_cache_version',\n",
+       " '_abc_registry',\n",
+       " '_check_is_fitted',\n",
+       " '_estimator_type',\n",
+       " '_format_results',\n",
+       " '_get_param_names',\n",
+       " '_get_tags',\n",
+       " '_required_parameters',\n",
+       " '_run_search',\n",
+       " 'best_estimator_',\n",
+       " 'best_index_',\n",
+       " 'best_params_',\n",
+       " 'best_score_',\n",
+       " 'classes_',\n",
+       " 'cv',\n",
+       " 'cv_results_',\n",
+       " 'decision_function',\n",
+       " 'error_score',\n",
+       " 'estimator',\n",
+       " 'fit',\n",
+       " 'get_params',\n",
+       " 'iid',\n",
+       " 'inverse_transform',\n",
+       " 'multimetric_',\n",
+       " 'n_jobs',\n",
+       " 'n_splits_',\n",
+       " 'param_grid',\n",
+       " 'pre_dispatch',\n",
+       " 'predict',\n",
+       " 'predict_log_proba',\n",
+       " 'predict_proba',\n",
+       " 'refit',\n",
+       " 'refit_time_',\n",
+       " 'return_train_score',\n",
+       " 'score',\n",
+       " 'scorer_',\n",
+       " 'scoring',\n",
+       " 'set_params',\n",
+       " 'transform',\n",
+       " 'verbose']"
       ]
      },
-     "execution_count": 6,
+     "execution_count": 29,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
+   "source": [
+    "dir(grid_result)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 7,
+   "metadata": {},
+   "outputs": [],
    "source": [
     "import wandb\n",
     "from wandb.keras import WandbCallback"
@@ -757,7 +955,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 9,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -774,7 +972,7 @@
        "\n",
        "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
        "                Project page: <a href=\"https://app.wandb.ai/lambda-ds7/boston\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston</a><br/>\n",
-       "                Run page: <a href=\"https://app.wandb.ai/lambda-ds7/boston/runs/kkgdtc31\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston/runs/kkgdtc31</a><br/>\n",
+       "                Run page: <a href=\"https://app.wandb.ai/lambda-ds7/boston/runs/178l6rec\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston/runs/178l6rec</a><br/>\n",
        "            "
       ],
       "text/plain": [
@@ -790,114 +988,114 @@
      "text": [
       "Train on 270 samples, validate on 134 samples\n",
       "Epoch 1/50\n",
-      "270/270 [==============================] - 1s 3ms/sample - loss: 492.3539 - mse: 492.3539 - mae: 20.3197 - val_loss: 481.5445 - val_mse: 481.5445 - val_mae: 19.6138\n",
+      "270/270 [==============================] - 1s 4ms/sample - loss: 507.5391 - mse: 507.5391 - mae: 20.8140 - val_loss: 519.8399 - val_mse: 519.8398 - val_mae: 20.6868\n",
       "Epoch 2/50\n",
-      "270/270 [==============================] - 0s 591us/sample - loss: 239.4999 - mse: 239.4999 - mae: 12.8064 - val_loss: 113.8561 - val_mse: 113.8561 - val_mae: 8.2962\n",
+      "270/270 [==============================] - 0s 450us/sample - loss: 304.5191 - mse: 304.5191 - mae: 15.1957 - val_loss: 180.1112 - val_mse: 180.1112 - val_mae: 10.4868\n",
       "Epoch 3/50\n",
-      "270/270 [==============================] - 0s 618us/sample - loss: 56.2921 - mse: 56.2921 - mae: 5.8988 - val_loss: 62.7912 - val_mse: 62.7912 - val_mae: 5.6465\n",
+      "270/270 [==============================] - 0s 452us/sample - loss: 67.6603 - mse: 67.6603 - mae: 6.2977 - val_loss: 81.1968 - val_mse: 81.1968 - val_mae: 6.5683\n",
       "Epoch 4/50\n",
-      "270/270 [==============================] - 0s 613us/sample - loss: 29.4994 - mse: 29.4994 - mae: 3.9653 - val_loss: 37.9256 - val_mse: 37.9256 - val_mae: 4.1730\n",
+      "270/270 [==============================] - 0s 473us/sample - loss: 38.0067 - mse: 38.0067 - mae: 4.5416 - val_loss: 53.2922 - val_mse: 53.2922 - val_mae: 4.9207\n",
       "Epoch 5/50\n",
-      "270/270 [==============================] - 0s 608us/sample - loss: 20.6919 - mse: 20.6919 - mae: 3.3022 - val_loss: 31.7489 - val_mse: 31.7489 - val_mae: 3.7113\n",
+      "270/270 [==============================] - 0s 520us/sample - loss: 25.9560 - mse: 25.9560 - mae: 3.6418 - val_loss: 42.8733 - val_mse: 42.8733 - val_mae: 4.2891\n",
       "Epoch 6/50\n",
-      "270/270 [==============================] - 0s 602us/sample - loss: 17.2701 - mse: 17.2701 - mae: 3.0291 - val_loss: 27.3921 - val_mse: 27.3921 - val_mae: 3.4958\n",
+      "270/270 [==============================] - 0s 476us/sample - loss: 20.8861 - mse: 20.8861 - mae: 3.2043 - val_loss: 35.0731 - val_mse: 35.0731 - val_mae: 3.8791\n",
       "Epoch 7/50\n",
-      "270/270 [==============================] - 0s 671us/sample - loss: 15.5172 - mse: 15.5172 - mae: 2.8537 - val_loss: 25.3208 - val_mse: 25.3208 - val_mae: 3.3650\n",
+      "270/270 [==============================] - 0s 564us/sample - loss: 17.9162 - mse: 17.9162 - mae: 3.0295 - val_loss: 32.2094 - val_mse: 32.2094 - val_mae: 3.6591\n",
       "Epoch 8/50\n",
-      "270/270 [==============================] - 0s 661us/sample - loss: 13.7548 - mse: 13.7548 - mae: 2.7089 - val_loss: 23.8920 - val_mse: 23.8920 - val_mae: 3.2746\n",
+      "270/270 [==============================] - 0s 520us/sample - loss: 15.5315 - mse: 15.5315 - mae: 2.8306 - val_loss: 28.2088 - val_mse: 28.2088 - val_mae: 3.3853\n",
       "Epoch 9/50\n",
-      "270/270 [==============================] - 0s 606us/sample - loss: 12.3745 - mse: 12.3745 - mae: 2.5662 - val_loss: 22.1294 - val_mse: 22.1294 - val_mae: 3.1509\n",
+      "270/270 [==============================] - 0s 475us/sample - loss: 14.0917 - mse: 14.0917 - mae: 2.6939 - val_loss: 26.5207 - val_mse: 26.5207 - val_mae: 3.2254\n",
       "Epoch 10/50\n",
-      "270/270 [==============================] - 0s 614us/sample - loss: 11.2424 - mse: 11.2424 - mae: 2.4804 - val_loss: 20.5718 - val_mse: 20.5718 - val_mae: 3.0461\n",
+      "270/270 [==============================] - 0s 497us/sample - loss: 12.3514 - mse: 12.3514 - mae: 2.5445 - val_loss: 23.4949 - val_mse: 23.4949 - val_mae: 3.0960\n",
       "Epoch 11/50\n",
-      "270/270 [==============================] - 0s 605us/sample - loss: 10.6098 - mse: 10.6098 - mae: 2.4178 - val_loss: 20.3467 - val_mse: 20.3467 - val_mae: 3.0251\n",
+      "270/270 [==============================] - 0s 485us/sample - loss: 11.7136 - mse: 11.7136 - mae: 2.5002 - val_loss: 22.6409 - val_mse: 22.6409 - val_mae: 3.0163\n",
       "Epoch 12/50\n",
-      "270/270 [==============================] - 0s 576us/sample - loss: 10.0011 - mse: 10.0011 - mae: 2.3257 - val_loss: 18.4283 - val_mse: 18.4283 - val_mae: 2.8938\n",
+      "270/270 [==============================] - 0s 537us/sample - loss: 11.1529 - mse: 11.1529 - mae: 2.4452 - val_loss: 20.9814 - val_mse: 20.9814 - val_mae: 2.8913\n",
       "Epoch 13/50\n",
-      "270/270 [==============================] - 0s 666us/sample - loss: 9.1287 - mse: 9.1287 - mae: 2.2384 - val_loss: 18.2024 - val_mse: 18.2024 - val_mae: 2.9116\n",
+      "270/270 [==============================] - 0s 455us/sample - loss: 10.2002 - mse: 10.2002 - mae: 2.3687 - val_loss: 20.9794 - val_mse: 20.9794 - val_mae: 2.8826\n",
       "Epoch 14/50\n",
-      "270/270 [==============================] - 0s 603us/sample - loss: 8.6211 - mse: 8.6211 - mae: 2.1980 - val_loss: 17.4749 - val_mse: 17.4749 - val_mae: 2.8290\n",
+      "270/270 [==============================] - 0s 471us/sample - loss: 9.7021 - mse: 9.7021 - mae: 2.3146 - val_loss: 19.0009 - val_mse: 19.0009 - val_mae: 2.7593\n",
       "Epoch 15/50\n",
-      "270/270 [==============================] - 0s 463us/sample - loss: 8.4558 - mse: 8.4558 - mae: 2.2087 - val_loss: 17.7878 - val_mse: 17.7878 - val_mae: 2.8516\n",
+      "270/270 [==============================] - 0s 533us/sample - loss: 9.0910 - mse: 9.0910 - mae: 2.2286 - val_loss: 18.6425 - val_mse: 18.6425 - val_mae: 2.7420\n",
       "Epoch 16/50\n",
-      "270/270 [==============================] - 0s 626us/sample - loss: 8.3626 - mse: 8.3626 - mae: 2.2031 - val_loss: 16.7101 - val_mse: 16.7101 - val_mae: 2.7820\n",
+      "270/270 [==============================] - 0s 421us/sample - loss: 8.7960 - mse: 8.7960 - mae: 2.2201 - val_loss: 19.4380 - val_mse: 19.4380 - val_mae: 2.8392\n",
       "Epoch 17/50\n",
-      "270/270 [==============================] - 0s 607us/sample - loss: 7.9180 - mse: 7.9180 - mae: 2.1265 - val_loss: 16.6064 - val_mse: 16.6064 - val_mae: 2.7419\n",
+      "270/270 [==============================] - 0s 504us/sample - loss: 8.2565 - mse: 8.2565 - mae: 2.1303 - val_loss: 17.7435 - val_mse: 17.7435 - val_mae: 2.6944\n",
       "Epoch 18/50\n",
-      "270/270 [==============================] - 0s 479us/sample - loss: 7.5552 - mse: 7.5552 - mae: 2.0235 - val_loss: 17.2872 - val_mse: 17.2872 - val_mae: 2.8539\n",
+      "270/270 [==============================] - 0s 365us/sample - loss: 7.8307 - mse: 7.8307 - mae: 2.0966 - val_loss: 18.2681 - val_mse: 18.2681 - val_mae: 2.7634\n",
       "Epoch 19/50\n",
-      "270/270 [==============================] - 0s 616us/sample - loss: 7.0971 - mse: 7.0971 - mae: 2.0038 - val_loss: 16.5110 - val_mse: 16.5110 - val_mae: 2.8042\n",
+      "270/270 [==============================] - 0s 477us/sample - loss: 8.3011 - mse: 8.3011 - mae: 2.1411 - val_loss: 17.3655 - val_mse: 17.3655 - val_mae: 2.6723\n",
       "Epoch 20/50\n",
-      "270/270 [==============================] - 0s 606us/sample - loss: 6.7068 - mse: 6.7068 - mae: 1.9539 - val_loss: 15.5886 - val_mse: 15.5886 - val_mae: 2.7048\n",
+      "270/270 [==============================] - 0s 418us/sample - loss: 8.0300 - mse: 8.0300 - mae: 2.1745 - val_loss: 18.0828 - val_mse: 18.0828 - val_mae: 2.7942\n",
       "Epoch 21/50\n",
-      "270/270 [==============================] - 0s 461us/sample - loss: 6.8542 - mse: 6.8542 - mae: 1.9979 - val_loss: 17.2378 - val_mse: 17.2378 - val_mae: 2.8853\n",
+      "270/270 [==============================] - 0s 477us/sample - loss: 7.3638 - mse: 7.3638 - mae: 2.0100 - val_loss: 18.0323 - val_mse: 18.0323 - val_mae: 2.7734\n",
       "Epoch 22/50\n",
-      "270/270 [==============================] - 0s 474us/sample - loss: 6.5719 - mse: 6.5719 - mae: 1.9312 - val_loss: 16.3043 - val_mse: 16.3043 - val_mae: 2.7756\n",
+      "270/270 [==============================] - 0s 412us/sample - loss: 7.9722 - mse: 7.9722 - mae: 2.1071 - val_loss: 18.5360 - val_mse: 18.5360 - val_mae: 2.8728\n",
       "Epoch 23/50\n",
-      "270/270 [==============================] - 0s 478us/sample - loss: 6.6161 - mse: 6.6161 - mae: 1.9572 - val_loss: 15.7992 - val_mse: 15.7992 - val_mae: 2.7219\n",
+      "270/270 [==============================] - 0s 508us/sample - loss: 7.2802 - mse: 7.2802 - mae: 1.9885 - val_loss: 16.5623 - val_mse: 16.5623 - val_mae: 2.6534\n",
       "Epoch 24/50\n",
-      "270/270 [==============================] - 0s 491us/sample - loss: 7.1269 - mse: 7.1269 - mae: 2.0137 - val_loss: 16.5402 - val_mse: 16.5402 - val_mae: 2.8005\n",
+      "270/270 [==============================] - 0s 364us/sample - loss: 6.7574 - mse: 6.7574 - mae: 1.9292 - val_loss: 16.6422 - val_mse: 16.6422 - val_mae: 2.6799\n",
       "Epoch 25/50\n",
-      "270/270 [==============================] - 0s 479us/sample - loss: 6.3382 - mse: 6.3382 - mae: 1.8540 - val_loss: 16.5034 - val_mse: 16.5034 - val_mae: 2.7864\n",
+      "270/270 [==============================] - 0s 518us/sample - loss: 7.0779 - mse: 7.0779 - mae: 1.9914 - val_loss: 16.3254 - val_mse: 16.3254 - val_mae: 2.6343\n",
       "Epoch 26/50\n",
-      "270/270 [==============================] - 0s 488us/sample - loss: 5.9442 - mse: 5.9442 - mae: 1.8251 - val_loss: 15.6558 - val_mse: 15.6558 - val_mae: 2.7102\n",
+      "270/270 [==============================] - 0s 347us/sample - loss: 6.4697 - mse: 6.4697 - mae: 1.9032 - val_loss: 16.6672 - val_mse: 16.6672 - val_mae: 2.6804\n",
       "Epoch 27/50\n",
-      "270/270 [==============================] - 0s 604us/sample - loss: 5.5832 - mse: 5.5832 - mae: 1.7432 - val_loss: 15.3021 - val_mse: 15.3021 - val_mae: 2.6862\n",
+      "270/270 [==============================] - 0s 367us/sample - loss: 6.6811 - mse: 6.6811 - mae: 1.9610 - val_loss: 17.2552 - val_mse: 17.2552 - val_mae: 2.7825\n",
       "Epoch 28/50\n",
-      "270/270 [==============================] - 0s 436us/sample - loss: 5.4530 - mse: 5.4530 - mae: 1.7354 - val_loss: 15.4570 - val_mse: 15.4570 - val_mae: 2.6846\n",
+      "270/270 [==============================] - 0s 352us/sample - loss: 6.4952 - mse: 6.4952 - mae: 1.9183 - val_loss: 16.5565 - val_mse: 16.5565 - val_mae: 2.6270\n",
       "Epoch 29/50\n",
-      "270/270 [==============================] - 0s 441us/sample - loss: 5.3070 - mse: 5.3070 - mae: 1.7079 - val_loss: 15.8510 - val_mse: 15.8510 - val_mae: 2.7644\n",
+      "270/270 [==============================] - 0s 499us/sample - loss: 5.9528 - mse: 5.9528 - mae: 1.8106 - val_loss: 16.2076 - val_mse: 16.2076 - val_mae: 2.6489\n",
       "Epoch 30/50\n",
-      "270/270 [==============================] - 0s 477us/sample - loss: 5.4157 - mse: 5.4157 - mae: 1.7321 - val_loss: 15.9160 - val_mse: 15.9160 - val_mae: 2.7134\n",
+      "270/270 [==============================] - 0s 334us/sample - loss: 6.1525 - mse: 6.1525 - mae: 1.8816 - val_loss: 16.8149 - val_mse: 16.8149 - val_mae: 2.7150\n",
       "Epoch 31/50\n",
-      "270/270 [==============================] - 0s 452us/sample - loss: 5.2639 - mse: 5.2639 - mae: 1.6981 - val_loss: 15.3554 - val_mse: 15.3554 - val_mae: 2.6662\n",
+      "270/270 [==============================] - 0s 357us/sample - loss: 6.1121 - mse: 6.1121 - mae: 1.8944 - val_loss: 17.8803 - val_mse: 17.8803 - val_mae: 2.8348\n",
       "Epoch 32/50\n",
-      "270/270 [==============================] - 0s 475us/sample - loss: 5.7687 - mse: 5.7687 - mae: 1.8045 - val_loss: 15.7151 - val_mse: 15.7151 - val_mae: 2.6867\n",
+      "270/270 [==============================] - 0s 329us/sample - loss: 5.9081 - mse: 5.9081 - mae: 1.8048 - val_loss: 16.4733 - val_mse: 16.4733 - val_mae: 2.6372\n",
       "Epoch 33/50\n",
-      "270/270 [==============================] - 0s 462us/sample - loss: 5.5210 - mse: 5.5210 - mae: 1.7367 - val_loss: 15.4227 - val_mse: 15.4227 - val_mae: 2.6561\n",
+      "270/270 [==============================] - 0s 335us/sample - loss: 5.8530 - mse: 5.8530 - mae: 1.7886 - val_loss: 17.0765 - val_mse: 17.0765 - val_mae: 2.7541\n",
       "Epoch 34/50\n",
-      "270/270 [==============================] - 0s 474us/sample - loss: 5.5663 - mse: 5.5663 - mae: 1.7294 - val_loss: 15.3376 - val_mse: 15.3376 - val_mae: 2.6991\n",
+      "270/270 [==============================] - 0s 349us/sample - loss: 5.6716 - mse: 5.6716 - mae: 1.7783 - val_loss: 16.5421 - val_mse: 16.5421 - val_mae: 2.7094\n",
       "Epoch 35/50\n",
-      "270/270 [==============================] - 0s 626us/sample - loss: 5.0063 - mse: 5.0063 - mae: 1.6196 - val_loss: 15.2642 - val_mse: 15.2642 - val_mae: 2.6796\n",
+      "270/270 [==============================] - 0s 460us/sample - loss: 5.5175 - mse: 5.5175 - mae: 1.7566 - val_loss: 16.1483 - val_mse: 16.1483 - val_mae: 2.6839\n",
       "Epoch 36/50\n",
-      "270/270 [==============================] - 0s 459us/sample - loss: 4.7251 - mse: 4.7251 - mae: 1.5727 - val_loss: 15.4858 - val_mse: 15.4858 - val_mae: 2.7288\n",
+      "270/270 [==============================] - 0s 352us/sample - loss: 5.4957 - mse: 5.4957 - mae: 1.7620 - val_loss: 16.4348 - val_mse: 16.4348 - val_mae: 2.6864\n",
       "Epoch 37/50\n",
-      "270/270 [==============================] - 0s 604us/sample - loss: 4.6394 - mse: 4.6394 - mae: 1.5854 - val_loss: 15.1139 - val_mse: 15.1139 - val_mae: 2.6305\n",
+      "270/270 [==============================] - 0s 364us/sample - loss: 5.4835 - mse: 5.4835 - mae: 1.7576 - val_loss: 16.4593 - val_mse: 16.4592 - val_mae: 2.6498\n",
       "Epoch 38/50\n",
-      "270/270 [==============================] - 0s 592us/sample - loss: 4.5669 - mse: 4.5669 - mae: 1.5548 - val_loss: 14.9898 - val_mse: 14.9898 - val_mae: 2.6340\n",
+      "270/270 [==============================] - 0s 460us/sample - loss: 5.0436 - mse: 5.0436 - mae: 1.6672 - val_loss: 15.8116 - val_mse: 15.8116 - val_mae: 2.6080\n",
       "Epoch 39/50\n",
-      "270/270 [==============================] - 0s 458us/sample - loss: 4.4480 - mse: 4.4480 - mae: 1.5334 - val_loss: 15.6389 - val_mse: 15.6389 - val_mae: 2.7337\n",
+      "270/270 [==============================] - 0s 368us/sample - loss: 5.0304 - mse: 5.0304 - mae: 1.6883 - val_loss: 16.8482 - val_mse: 16.8482 - val_mae: 2.7210\n",
       "Epoch 40/50\n",
-      "270/270 [==============================] - 0s 455us/sample - loss: 4.4119 - mse: 4.4119 - mae: 1.5426 - val_loss: 15.0723 - val_mse: 15.0723 - val_mae: 2.6709\n",
+      "270/270 [==============================] - 0s 489us/sample - loss: 5.1982 - mse: 5.1982 - mae: 1.7064 - val_loss: 15.7318 - val_mse: 15.7318 - val_mae: 2.5719\n",
       "Epoch 41/50\n",
-      "270/270 [==============================] - 0s 473us/sample - loss: 4.0797 - mse: 4.0797 - mae: 1.4725 - val_loss: 15.4706 - val_mse: 15.4706 - val_mae: 2.6707\n",
+      "270/270 [==============================] - 0s 638us/sample - loss: 5.0634 - mse: 5.0634 - mae: 1.6976 - val_loss: 15.4289 - val_mse: 15.4289 - val_mae: 2.5781\n",
       "Epoch 42/50\n",
-      "270/270 [==============================] - 0s 449us/sample - loss: 4.0619 - mse: 4.0619 - mae: 1.4692 - val_loss: 15.2423 - val_mse: 15.2423 - val_mae: 2.6165\n",
+      "270/270 [==============================] - 0s 465us/sample - loss: 4.7731 - mse: 4.7731 - mae: 1.6470 - val_loss: 15.7236 - val_mse: 15.7236 - val_mae: 2.6185\n",
       "Epoch 43/50\n",
-      "270/270 [==============================] - 0s 465us/sample - loss: 4.1861 - mse: 4.1861 - mae: 1.5076 - val_loss: 15.7510 - val_mse: 15.7510 - val_mae: 2.7279\n",
+      "270/270 [==============================] - 0s 384us/sample - loss: 4.8663 - mse: 4.8663 - mae: 1.6506 - val_loss: 15.5836 - val_mse: 15.5836 - val_mae: 2.6002\n",
       "Epoch 44/50\n",
-      "270/270 [==============================] - 0s 462us/sample - loss: 4.1128 - mse: 4.1128 - mae: 1.4810 - val_loss: 15.4814 - val_mse: 15.4814 - val_mae: 2.6562\n",
+      "270/270 [==============================] - 0s 430us/sample - loss: 4.3547 - mse: 4.3547 - mae: 1.5646 - val_loss: 15.9491 - val_mse: 15.9491 - val_mae: 2.5998\n",
       "Epoch 45/50\n",
-      "270/270 [==============================] - 0s 441us/sample - loss: 4.2171 - mse: 4.2171 - mae: 1.5205 - val_loss: 16.3839 - val_mse: 16.3839 - val_mae: 2.8194\n",
+      "270/270 [==============================] - 0s 413us/sample - loss: 4.6104 - mse: 4.6104 - mae: 1.5876 - val_loss: 15.5854 - val_mse: 15.5854 - val_mae: 2.5998\n",
       "Epoch 46/50\n",
-      "270/270 [==============================] - 0s 422us/sample - loss: 4.2609 - mse: 4.2609 - mae: 1.5548 - val_loss: 15.3587 - val_mse: 15.3587 - val_mae: 2.7161\n",
+      "270/270 [==============================] - 0s 355us/sample - loss: 4.4646 - mse: 4.4646 - mae: 1.5908 - val_loss: 15.4599 - val_mse: 15.4599 - val_mae: 2.5814\n",
       "Epoch 47/50\n",
-      "270/270 [==============================] - 0s 454us/sample - loss: 4.4635 - mse: 4.4635 - mae: 1.5440 - val_loss: 15.7736 - val_mse: 15.7736 - val_mae: 2.7184\n",
+      "270/270 [==============================] - 0s 398us/sample - loss: 4.4594 - mse: 4.4594 - mae: 1.5573 - val_loss: 15.5114 - val_mse: 15.5114 - val_mae: 2.5725\n",
       "Epoch 48/50\n",
-      "270/270 [==============================] - 0s 426us/sample - loss: 3.7406 - mse: 3.7406 - mae: 1.4147 - val_loss: 15.6718 - val_mse: 15.6718 - val_mae: 2.7468\n",
+      "270/270 [==============================] - 0s 356us/sample - loss: 4.2764 - mse: 4.2764 - mae: 1.5469 - val_loss: 16.2340 - val_mse: 16.2340 - val_mae: 2.6444\n",
       "Epoch 49/50\n",
-      "270/270 [==============================] - 0s 445us/sample - loss: 3.6173 - mse: 3.6173 - mae: 1.3816 - val_loss: 15.7291 - val_mse: 15.7291 - val_mae: 2.7789\n",
+      "270/270 [==============================] - 0s 412us/sample - loss: 4.6540 - mse: 4.6540 - mae: 1.6044 - val_loss: 15.4722 - val_mse: 15.4722 - val_mae: 2.5458\n",
       "Epoch 50/50\n",
-      "270/270 [==============================] - 0s 430us/sample - loss: 3.6303 - mse: 3.6303 - mae: 1.4266 - val_loss: 15.4937 - val_mse: 15.4937 - val_mae: 2.7390\n"
+      "270/270 [==============================] - 0s 399us/sample - loss: 4.3385 - mse: 4.3385 - mae: 1.5542 - val_loss: 15.5644 - val_mse: 15.5644 - val_mae: 2.6206\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x7f315c319be0>"
+       "<tensorflow.python.keras.callbacks.History at 0x7efc563df198>"
       ]
      },
-     "execution_count": 8,
+     "execution_count": 9,
      "metadata": {},
      "output_type": "execute_result"
     }
